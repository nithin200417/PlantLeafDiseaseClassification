{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ffc0032",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-05-05T22:27:56.192888Z",
     "iopub.status.busy": "2024-05-05T22:27:56.192608Z",
     "iopub.status.idle": "2024-05-05T22:28:12.532738Z",
     "shell.execute_reply": "2024-05-05T22:28:12.531677Z"
    },
    "papermill": {
     "duration": 16.348528,
     "end_time": "2024-05-05T22:28:12.535037",
     "exception": false,
     "start_time": "2024-05-05T22:27:56.186509",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install ultralytics -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a95f8868",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T22:28:12.546147Z",
     "iopub.status.busy": "2024-05-05T22:28:12.545857Z",
     "iopub.status.idle": "2024-05-05T22:28:20.131321Z",
     "shell.execute_reply": "2024-05-05T22:28:20.130559Z"
    },
    "papermill": {
     "duration": 7.593497,
     "end_time": "2024-05-05T22:28:20.133763",
     "exception": false,
     "start_time": "2024-05-05T22:28:12.540266",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "997bd209",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T22:28:20.144461Z",
     "iopub.status.busy": "2024-05-05T22:28:20.143854Z",
     "iopub.status.idle": "2024-05-05T22:28:21.103499Z",
     "shell.execute_reply": "2024-05-05T22:28:21.102452Z"
    },
    "papermill": {
     "duration": 0.967478,
     "end_time": "2024-05-05T22:28:21.105974",
     "exception": false,
     "start_time": "2024-05-05T22:28:20.138496",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov9c.pt to 'yolov9c.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 49.4M/49.4M [00:00<00:00, 212MB/s]\n"
     ]
    }
   ],
   "source": [
    "model = YOLO('yolov9c.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fc2cd7a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T22:28:21.117573Z",
     "iopub.status.busy": "2024-05-05T22:28:21.117262Z",
     "iopub.status.idle": "2024-05-05T22:28:22.071484Z",
     "shell.execute_reply": "2024-05-05T22:28:22.070211Z"
    },
    "papermill": {
     "duration": 0.962381,
     "end_time": "2024-05-05T22:28:22.073831",
     "exception": false,
     "start_time": "2024-05-05T22:28:21.111450",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!touch data.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0e1c3d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T22:28:22.085374Z",
     "iopub.status.busy": "2024-05-05T22:28:22.085044Z",
     "iopub.status.idle": "2024-05-05T22:28:22.090765Z",
     "shell.execute_reply": "2024-05-05T22:28:22.089920Z"
    },
    "papermill": {
     "duration": 0.013592,
     "end_time": "2024-05-05T22:28:22.092612",
     "exception": false,
     "start_time": "2024-05-05T22:28:22.079020",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "write='''train: /kaggle/input/uma-pro/train/images\n",
    "val: /kaggle/input/uma-pro/val/images\n",
    "\n",
    "nc: 1\n",
    "names: ['Diseased']'''\n",
    "with open(\"/kaggle/working/data.yaml\", \"w\") as file:\n",
    "    file.write(write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5267960e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T22:28:22.103626Z",
     "iopub.status.busy": "2024-05-05T22:28:22.103362Z",
     "iopub.status.idle": "2024-05-05T22:28:50.572010Z",
     "shell.execute_reply": "2024-05-05T22:28:50.570560Z"
    },
    "papermill": {
     "duration": 28.476136,
     "end_time": "2024-05-05T22:28:50.573751",
     "exception": true,
     "start_time": "2024-05-05T22:28:22.097615",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.9 ðŸš€ Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla T4, 15102MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov9c.pt, data=/kaggle/working/data.yaml, epochs=20, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n",
      "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 755k/755k [00:00<00:00, 14.5MB/s]\n",
      "2024-05-05 22:28:25,330\tINFO util.py:124 -- Outdated packages:\n",
      "  ipywidgets==7.7.1 found, needs ipywidgets>=8\n",
      "Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2024-05-05 22:28:27,619\tINFO util.py:124 -- Outdated packages:\n",
      "  ipywidgets==7.7.1 found, needs ipywidgets>=8\n",
      "Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2024-05-05 22:28:31.800922: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-05 22:28:31.801052: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-05 22:28:32.096148: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
      "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  2                  -1  1    212864  ultralytics.nn.modules.block.RepNCSPELAN4    [128, 256, 128, 64, 1]        \n",
      "  3                  -1  1    164352  ultralytics.nn.modules.block.ADown           [256, 256]                    \n",
      "  4                  -1  1    847616  ultralytics.nn.modules.block.RepNCSPELAN4    [256, 512, 256, 128, 1]       \n",
      "  5                  -1  1    656384  ultralytics.nn.modules.block.ADown           [512, 512]                    \n",
      "  6                  -1  1   2857472  ultralytics.nn.modules.block.RepNCSPELAN4    [512, 512, 512, 256, 1]       \n",
      "  7                  -1  1    656384  ultralytics.nn.modules.block.ADown           [512, 512]                    \n",
      "  8                  -1  1   2857472  ultralytics.nn.modules.block.RepNCSPELAN4    [512, 512, 512, 256, 1]       \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPELAN         [512, 512, 256]               \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1   3119616  ultralytics.nn.modules.block.RepNCSPELAN4    [1024, 512, 512, 256, 1]      \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    912640  ultralytics.nn.modules.block.RepNCSPELAN4    [1024, 256, 256, 128, 1]      \n",
      " 16                  -1  1    164352  ultralytics.nn.modules.block.ADown           [256, 256]                    \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1   2988544  ultralytics.nn.modules.block.RepNCSPELAN4    [768, 512, 512, 256, 1]       \n",
      " 19                  -1  1    656384  ultralytics.nn.modules.block.ADown           [512, 512]                    \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   3119616  ultralytics.nn.modules.block.RepNCSPELAN4    [1024, 512, 512, 256, 1]      \n",
      " 22        [15, 18, 21]  1   5583571  ultralytics.nn.modules.head.Detect           [1, [256, 512, 512]]          \n",
      "YOLOv9c summary: 618 layers, 25530003 parameters, 25529987 gradients, 103.7 GFLOPs\n",
      "\n",
      "Transferred 931/937 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "ename": "UsageError",
     "evalue": "api_key not configured (no-tty). call wandb.login(key=[your_api_key])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUsageError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/kaggle/working/data.yaml\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/ultralytics/engine/model.py:673\u001b[0m, in \u001b[0;36mModel.train\u001b[0;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[1;32m    670\u001b[0m             \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mhub_session \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession  \u001b[38;5;66;03m# attach optional HUB session\u001b[39;00m\n\u001b[0;32m--> 673\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[38;5;66;03m# Update model and cfg after training\u001b[39;00m\n\u001b[1;32m    675\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m}:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/ultralytics/engine/trainer.py:199\u001b[0m, in \u001b[0;36mBaseTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    196\u001b[0m         ddp_cleanup(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mstr\u001b[39m(file))\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 199\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mworld_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/ultralytics/engine/trainer.py:313\u001b[0m, in \u001b[0;36mBaseTrainer._do_train\u001b[0;34m(self, world_size)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m world_size \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setup_ddp(world_size)\n\u001b[0;32m--> 313\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setup_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mworld_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    315\u001b[0m nb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_loader)  \u001b[38;5;66;03m# number of batches\u001b[39;00m\n\u001b[1;32m    316\u001b[0m nw \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mround\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mwarmup_epochs \u001b[38;5;241m*\u001b[39m nb), \u001b[38;5;241m100\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mwarmup_epochs \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# warmup iterations\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/ultralytics/engine/trainer.py:226\u001b[0m, in \u001b[0;36mBaseTrainer._setup_train\u001b[0;34m(self, world_size)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Builds dataloaders and optimizer on correct rank process.\"\"\"\u001b[39;00m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;66;03m# Model\u001b[39;00m\n\u001b[0;32m--> 226\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_callbacks\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mon_pretrain_routine_start\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    227\u001b[0m ckpt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msetup_model()\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/ultralytics/engine/trainer.py:162\u001b[0m, in \u001b[0;36mBaseTrainer.run_callbacks\u001b[0;34m(self, event)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Run all existing callbacks associated with a particular event.\"\"\"\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mget(event, []):\n\u001b[0;32m--> 162\u001b[0m     \u001b[43mcallback\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/ultralytics/utils/callbacks/wb.py:112\u001b[0m, in \u001b[0;36mon_pretrain_routine_start\u001b[0;34m(trainer)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_pretrain_routine_start\u001b[39m(trainer):\n\u001b[1;32m    111\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Initiate and start project if module is present.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 112\u001b[0m     wb\u001b[38;5;241m.\u001b[39mrun \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mwb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproject\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mYOLOv8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mvars\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_init.py:1200\u001b[0m, in \u001b[0;36minit\u001b[0;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, fork_from, settings)\u001b[0m\n\u001b[1;32m   1198\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m logger \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1199\u001b[0m         logger\u001b[38;5;241m.\u001b[39mexception(\u001b[38;5;28mstr\u001b[39m(e))\n\u001b[0;32m-> 1200\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m   1201\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1202\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m logger\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_init.py:1177\u001b[0m, in \u001b[0;36minit\u001b[0;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, fork_from, settings)\u001b[0m\n\u001b[1;32m   1175\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1176\u001b[0m     wi \u001b[38;5;241m=\u001b[39m _WandbInit()\n\u001b[0;32m-> 1177\u001b[0m     \u001b[43mwi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1178\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m wi\u001b[38;5;241m.\u001b[39msettings\n\u001b[1;32m   1179\u001b[0m     except_exit \u001b[38;5;241m=\u001b[39m wi\u001b[38;5;241m.\u001b[39msettings\u001b[38;5;241m.\u001b[39m_except_exit\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_init.py:301\u001b[0m, in \u001b[0;36m_WandbInit.setup\u001b[0;34m(self, kwargs)\u001b[0m\n\u001b[1;32m    298\u001b[0m     settings\u001b[38;5;241m.\u001b[39mupdate(init_settings, source\u001b[38;5;241m=\u001b[39mSource\u001b[38;5;241m.\u001b[39mINIT)\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m settings\u001b[38;5;241m.\u001b[39m_offline \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m settings\u001b[38;5;241m.\u001b[39m_noop:\n\u001b[0;32m--> 301\u001b[0m     \u001b[43mwandb_login\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_login\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m        \u001b[49m\u001b[43manonymous\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43manonymous\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforce\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_disable_warning\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_silent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msettings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquiet\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msettings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msilent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_entity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mentity\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msettings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mentity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;66;03m# apply updated global state after login was handled\u001b[39;00m\n\u001b[1;32m    310\u001b[0m wl \u001b[38;5;241m=\u001b[39m wandb\u001b[38;5;241m.\u001b[39msetup()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_login.py:334\u001b[0m, in \u001b[0;36m_login\u001b[0;34m(anonymous, key, relogin, host, force, timeout, _backend, _silent, _disable_warning, _entity)\u001b[0m\n\u001b[1;32m    331\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m logged_in\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m key:\n\u001b[0;32m--> 334\u001b[0m     \u001b[43mwlogin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprompt_api_key\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    336\u001b[0m \u001b[38;5;66;03m# make sure login credentials get to the backend\u001b[39;00m\n\u001b[1;32m    337\u001b[0m wlogin\u001b[38;5;241m.\u001b[39mpropogate_login()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_login.py:263\u001b[0m, in \u001b[0;36m_WandbLogin.prompt_api_key\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m==\u001b[39m ApiKeyStatus\u001b[38;5;241m.\u001b[39mNOTTY:\n\u001b[1;32m    258\u001b[0m     directive \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwandb login [your_api_key]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_settings\u001b[38;5;241m.\u001b[39m_cli_only_mode\n\u001b[1;32m    261\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwandb.login(key=[your_api_key])\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    262\u001b[0m     )\n\u001b[0;32m--> 263\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m UsageError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapi_key not configured (no-tty). call \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m directive)\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_session(key, status\u001b[38;5;241m=\u001b[39mstatus)\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_key \u001b[38;5;241m=\u001b[39m key\n",
      "\u001b[0;31mUsageError\u001b[0m: api_key not configured (no-tty). call wandb.login(key=[your_api_key])"
     ]
    }
   ],
   "source": [
    "model.train(data='/kaggle/working/data.yaml', epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480f118d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T16:48:26.750394Z",
     "iopub.status.busy": "2024-05-05T16:48:26.750050Z",
     "iopub.status.idle": "2024-05-05T16:48:27.596082Z",
     "shell.execute_reply": "2024-05-05T16:48:27.595203Z",
     "shell.execute_reply.started": "2024-05-05T16:48:26.750359Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the image\n",
    "img_path = '/kaggle/input/new-plant-diseases-dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train/Pepper,_bell___Bacterial_spot/01613cd0-d3cd-4e96-945c-a312002037bf___JR_B.Spot 3262_180deg.JPG'\n",
    "img = cv2.imread(img_path)\n",
    "\n",
    "# Convert color space from BGR to RGB\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Perform detection\n",
    "results = model.predict(img)\n",
    "\n",
    "# Get the boxes attribute from the first result\n",
    "boxes = results[0].boxes\n",
    "\n",
    "# Visualize the bounding boxes and save them as separate images\n",
    "for i, box in enumerate(boxes.xyxy):\n",
    "    x1, y1, x2, y2 = map(int, box.tolist())  # Convert coordinates to integers\n",
    "\n",
    "    # Crop the region of interest from the image\n",
    "    roi = img[y1:y2, x1:x2]\n",
    "\n",
    "    # Save the region of interest as a separate image\n",
    "    cv2.imwrite(f'roi_{i}.png', cv2.cvtColor(roi, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "    # Display the region of interest\n",
    "    plt.imshow(roi)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36b11f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T16:48:27.597988Z",
     "iopub.status.busy": "2024-05-05T16:48:27.597524Z",
     "iopub.status.idle": "2024-05-05T16:48:28.288072Z",
     "shell.execute_reply": "2024-05-05T16:48:28.287088Z",
     "shell.execute_reply.started": "2024-05-05T16:48:27.597950Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms, models\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# Load the ShuffleNetV2 model\n",
    "shufflenet = models.shufflenet_v2_x1_0(pretrained=True)\n",
    "shufflenet.eval()\n",
    "\n",
    "# Define the image transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Load the image\n",
    "img_path = '/kaggle/input/new-plant-diseases-dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train/Pepper,_bell___Bacterial_spot/01613cd0-d3cd-4e96-945c-a312002037bf___JR_B.Spot 3262_180deg.JPG'\n",
    "img = cv2.imread(img_path)\n",
    "\n",
    "# Convert color space from BGR to RGB\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Perform detection\n",
    "results = model.predict(img)\n",
    "\n",
    "# Get the boxes attribute from the first result\n",
    "boxes = results[0].boxes\n",
    "\n",
    "# Visualize the bounding boxes and save them as separate images\n",
    "for i, box in enumerate(boxes.xyxy):\n",
    "    x1, y1, x2, y2 = map(int, box.tolist())  # Convert coordinates to integers\n",
    "\n",
    "    # Crop the region of interest from the image\n",
    "    roi = img[y1:y2, x1:x2]\n",
    "\n",
    "    # Save the region of interest as a separate image\n",
    "    cv2.imwrite(f'roi_{i}.png', cv2.cvtColor(roi, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "    # Display the region of interest\n",
    "    plt.imshow(roi)\n",
    "    plt.show()\n",
    "\n",
    "    # Transform the ROI and add a batch dimension\n",
    "    input = transform(roi).unsqueeze(0)\n",
    "\n",
    "    # Convert the input to a Variable\n",
    "    input = Variable(input)\n",
    "\n",
    "    # Perform inference with the ShuffleNetV2 model\n",
    "    output = shufflenet(input)\n",
    "\n",
    "    # Print the output\n",
    "    print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41522451",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T16:48:28.289625Z",
     "iopub.status.busy": "2024-05-05T16:48:28.289337Z",
     "iopub.status.idle": "2024-05-05T16:48:29.178734Z",
     "shell.execute_reply": "2024-05-05T16:48:29.177720Z",
     "shell.execute_reply.started": "2024-05-05T16:48:28.289600Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms, models\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# Load the ShuffleNetV2 model\n",
    "shufflenet = models.shufflenet_v2_x1_0(pretrained=True)\n",
    "shufflenet.eval()\n",
    "\n",
    "# Define the image transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Load the image\n",
    "img_path = '/kaggle/input/new-plant-diseases-dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train/Grape___Black_rot/012658ed-f0a3-4791-a996-7115dd1e6e3b___FAM_B.Rot 3036.JPG'\n",
    "img = cv2.imread(img_path)\n",
    "plt.imshow(img)\n",
    "\n",
    "# Convert color space from BGR to RGB\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Perform detection\n",
    "results = model.predict(img)\n",
    "\n",
    "# Get the boxes attribute from the first result\n",
    "boxes = results[0].boxes\n",
    "\n",
    "# Visualize the bounding boxes and save them as separate images\n",
    "for i, box in enumerate(boxes.xyxy):\n",
    "    x1, y1, x2, y2 = map(int, box.tolist())  # Convert coordinates to integers\n",
    "\n",
    "    # Crop the region of interest from the image\n",
    "    roi = img[y1:y2, x1:x2]\n",
    "\n",
    "    # Save the region of interest as a separate image\n",
    "    cv2.imwrite(f'roi_{i}.png', cv2.cvtColor(roi, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "    # Display the region of interest\n",
    "    plt.imshow(roi)\n",
    "    plt.show()\n",
    "\n",
    "    # Transform the ROI and add a batch dimension\n",
    "    input = transform(roi).unsqueeze(0)\n",
    "\n",
    "    # Convert the input to a Variable\n",
    "    input = Variable(input)\n",
    "\n",
    "    # Perform inference with the ShuffleNetV2 model\n",
    "    output = shufflenet(input)\n",
    "\n",
    "    # Print the output\n",
    "    print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b70895",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T17:10:56.110081Z",
     "iopub.status.busy": "2024-05-05T17:10:56.109513Z",
     "iopub.status.idle": "2024-05-05T17:11:07.913581Z",
     "shell.execute_reply": "2024-05-05T17:11:07.912779Z",
     "shell.execute_reply.started": "2024-05-05T17:10:56.110048Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "class PlantDiseaseDataset(Dataset):\n",
    "    def __init__(self, img_dir, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.img_paths = [os.path.join(root, img)\n",
    "                          for root, _, imgs in os.walk(img_dir)\n",
    "                          for img in imgs if img.endswith(\".jpg\")]\n",
    "        self.transform = transform\n",
    "\n",
    "        # Extract class names from the directory structure\n",
    "        self.classes = sorted({os.path.basename(os.path.dirname(img_path)) for img_path in self.img_paths})\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.img_paths[idx]\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            raise ValueError(f\"Could not load image at {img_path}. Check that the file exists and is a valid image file.\")\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        else:\n",
    "            img = torch.from_numpy(img)\n",
    "\n",
    "        # Determine the label of the image based on the subdirectory it's in\n",
    "        label = os.path.basename(os.path.dirname(img_path))\n",
    "\n",
    "        return img, label\n",
    "\n",
    "# Define the image transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Load the YOLO model and the plant disease classification model\n",
    "classification_model = models.shufflenet_v2_x1_0(pretrained=True)  # replace with your model\n",
    "classification_model.fc = torch.nn.Linear(in_features=1024, out_features=38)  # adjust the last layer to match the number of classes in your dataset\n",
    "classification_model.train()\n",
    "\n",
    "# Create a CLAHE object\n",
    "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "\n",
    "# Load your dataset\n",
    "dataset = PlantDiseaseDataset('/kaggle/input/new-plant-diseases-dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train/', transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Define your loss function and optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(classification_model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e893d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T18:28:35.994149Z",
     "iopub.status.busy": "2024-05-05T18:28:35.993748Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a dictionary that maps class names to indices\n",
    "class_to_idx = {class_name: i for i, class_name in enumerate(dataset.classes)}\n",
    "\n",
    "for epoch in range(100):  # replace num_epochs with the number of epochs you want to train for\n",
    "    for inputs, labels in dataloader:\n",
    "        # Convert tensor to numpy array\n",
    "        inputs_np = inputs.numpy()\n",
    "\n",
    "        # Apply CLAHE to each channel in the image\n",
    "        for i in range(inputs_np.shape[0]):  # iterate over batch dimension\n",
    "            img = inputs_np[i].transpose((1, 2, 0))  # convert to (height, width, channels)\n",
    "            for j in range(img.shape[2]):  # iterate over color channels\n",
    "                img[:, :, j] = clahe.apply((img[:, :, j]*255).astype(np.uint8))\n",
    "            inputs_np[i] = img.transpose((2, 0, 1))  # convert back to (channels, height, width)\n",
    "\n",
    "        # Convert numpy array back to tensor\n",
    "        inputs = torch.from_numpy(inputs_np)\n",
    "\n",
    "        # Perform detection with the YOLO model\n",
    "        results = model.predict(inputs)\n",
    "\n",
    "        # Get the boxes attribute from the first result\n",
    "        boxes = results[0].boxes\n",
    "\n",
    "        # Extract the ROIs from the image and use them as input for the ShuffleNetV2 model\n",
    "        rois = []\n",
    "        roi_labels = []\n",
    "        for i, box in enumerate(boxes.xyxy):\n",
    "            x1, y1, x2, y2 = map(int, box.tolist())  # Convert coordinates to integers\n",
    "\n",
    "            # Ensure the bounding box coordinates are within the range of the image dimensions\n",
    "            x1 = max(0, min(x1, inputs.shape[3] - 1))\n",
    "            y1 = max(0, min(y1, inputs.shape[2] - 1))\n",
    "            x2 = max(0, min(x2, inputs.shape[3] - 1))\n",
    "            y2 = max(0, min(y2, inputs.shape[2] - 1))\n",
    "\n",
    "            # Ensure x1 is less than x2 and y1 is less than y2\n",
    "            if x1 < x2 and y1 < y2:\n",
    "                # Crop the region of interest from the image\n",
    "                roi = inputs[i, :, y1:y2, x1:x2]\n",
    "                \n",
    "                # Resize the ROI to a fixed size (e.g., 224x224)\n",
    "                roi = transforms.Resize((224, 224))(roi)\n",
    "                \n",
    "                rois.append(roi)\n",
    "                roi_labels.append(class_to_idx[labels[i]])\n",
    "\n",
    "        # Check if the rois list is empty\n",
    "        if not rois:\n",
    "            continue\n",
    "\n",
    "        # Convert lists to tensors\n",
    "        rois = torch.stack(rois)\n",
    "        roi_labels = torch.tensor(roi_labels).to(inputs.device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = classification_model(rois)\n",
    "        loss = criterion(outputs, roi_labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be03a13",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the test dataset\n",
    "test_dataset = PlantDiseaseDataset('/kaggle/input/new-plant-diseases-dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/valid/', transform=transform)\n",
    "print(f\"Number of images in the test dataset: {len(test_dataset)}\")\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32)\n",
    "print(f\"Number of batches in the test dataloader: {len(test_dataloader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f4fda6",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# No need to track gradients in evaluation mode\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_dataloader:\n",
    "        # Convert labels to indices\n",
    "        labels_idx = torch.tensor([class_to_idx[label] for label in labels]).to(inputs.device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = classification_model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        # Update the number of total and correct predictions\n",
    "        total_predictions += labels_idx.size(0)\n",
    "        correct_predictions += (predicted == labels_idx).sum().item()\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = correct_predictions / total_predictions\n",
    "print(f'Accuracy of the model on the test images: {accuracy * 100}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81952db9",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 78313,
     "sourceId": 182633,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4942913,
     "sourceId": 8321268,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30699,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 61.039061,
   "end_time": "2024-05-05T22:28:53.242940",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-05-05T22:27:52.203879",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
